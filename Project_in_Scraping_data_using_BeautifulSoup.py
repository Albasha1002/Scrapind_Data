# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cm4RYDbDxROT9KKscg8a-9jpQHbCMRDi
"""

import requests
from bs4 import BeautifulSoup
url="https://www.goodreads.com/quotes/tag/{}?page={}"

def get_quotes(url):
        res=requests.get(url)
        soup=BeautifulSoup(res.text)
        quotes_div=soup.find_all("div", attrs={"class":"quote"})
        quotes=[]
        for quote_div in quotes_div:
                quote_Text=quote_div.find_next("div", attrs={"class":"quoteText"})
                striped=quote_Text.text.strip()
                striped_li=striped.split("\n")
                quote=striped_li[0][1:-1]
                author=striped_li[-1].strip()

                left_div=quote_div.find_next("div", attrs={"class":"greyText"})
                tags=[tag.text for tag in left_div.find_all("a")]
                quote_item={
                    "text":quote,
                    "author":author,
                    "tags":tags
                }
                quotes.append(quote_item)
        return quotes
total=[]
for i in range(1,6):
  total.extend(get_quotes(url.format("love",i)))
  print("processed",i)

total

len(total)

total

import pandas as pd

df=pd.DataFrame(total)

df.to_csv("scrap.csv")

